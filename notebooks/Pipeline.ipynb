{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7eab85d-9282-410e-98ef-0ac9ba8e89dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment\")\n",
    "!pip install -q -r requirements.txt\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "from trading_functions import *\n",
    "# Core Libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import warnings\n",
    "import itertools\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all messages, 1 = info, 2 = warnings, 3 = errors\n",
    "\n",
    "# Data Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Financial Data\n",
    "import yfinance as yf\n",
    "import quantstats as qs\n",
    "import ta\n",
    "\n",
    "# Machine Learning - Supervised Learning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Machine Learning - Deep Learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "# Reinforcement Learning and Environments\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import A2C, DDPG, DQN, HER, PPO, SAC, TD3\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import (\n",
    "    EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    ")\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecCheckNan, VecNormalize\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sb3_contrib import ARS, MaskablePPO, RecurrentPPO, QRDQN, TRPO\n",
    "\n",
    "# Imitation Learning\n",
    "from imitation.algorithms import bc\n",
    "from imitation.testing.reward_improvement import is_significant_reward_improvement\n",
    "from imitation.data.types import Transitions\n",
    "\n",
    "# Interactive Brokers API\n",
    "from ib_insync import *\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a2744c5-824e-49c4-aabe-cadc53d52d71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "SEED = 1\n",
    "history_length = [1, 2, 4, 5, 6, 8, 10, 16, 20]\n",
    "reward_type = 'LNR'\n",
    "stocks = ['AAPL', 'AMZN', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2023-06-30'\n",
    "stock_list = ['AAPL', 'ABBV', 'ADBE', 'AES', 'AMAT', 'AMCR', 'AMD', 'AMZN', 'ANET', 'APA', 'APH', 'AVGO', 'BA', 'BAC', 'BMY', 'C', 'CCI', 'CCL', 'CMCSA', 'CMG', 'CNC', 'CNP', 'COP', 'CRM', 'CSCO', 'CSX', 'CTRA', 'CVS', 'CVX', 'DAL', 'DIS', 'DVN', 'EQT', 'EW', 'EXC', 'F', 'FCX', 'GE', 'GILD', 'GIS', 'GM', 'GOOG', 'GOOGL', 'HAL', 'HBAN', 'HPQ', 'HST', 'INTC', 'IPG', 'JNJ', 'JPM', 'KDP', 'KEY', 'KMI', 'KO', 'LRCX', 'LUV', 'MCHP', 'MDLZ', 'MDT', 'META', 'MO', 'MRK', 'MS', 'MSFT', 'MU', 'NCLH', 'NEE', 'NEM', 'NKE', 'NVDA', 'ON', 'ORCL', 'OXY', 'PARA', 'PCG', 'PEP', 'PFE', 'PG', 'QCOM', 'RF', 'SBUX', 'SCHW', 'SLB', 'SMCI', 'T', 'TFC', 'TJX', 'TSLA', 'UNH', 'USB', 'V', 'VTRS', 'VZ', 'WBA', 'WBD', 'WDC', 'WFC', 'WMB', 'WMT', 'XOM']\n",
    "stock_list = sorted(stock_list)\n",
    "n_envs = 8\n",
    "n_steps = 16\n",
    "total_timesteps = 10_000\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "ent_coef = 0.05\n",
    "log_interval = 1_000\n",
    "eval_freq = 1_000\n",
    "model_name= 'A2C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19a4b6db-bad6-4aa7-a1ee-eca900f0f7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_false = np.isnan(data.iloc[0]['Close'].values) == False\n",
    "stock_list = np.array(stock_list)  # Ensure it's an array if indexing is required.\n",
    "stock_list = list(stock_list[index_false])  # Outputs: array(['AAPL', 'MSFT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21da0ae0-5e55-4135-97ca-bdd47a25ebd3",
   "metadata": {},
   "source": [
    "Stage 1: Set time intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e52826e-f2fa-4170-887c-087956c58b3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training environment\n",
    "env = create_training_env(history_length[-1], reward_type, start_date, end_date, stocks, n_envs)[0]\n",
    "\n",
    "# Compute the differences with the next number\n",
    "differences = [history_length[i + 1] - history_length[i] for i in range(len(history_length) - 1)]\n",
    "# Append a placeholder for the last element\n",
    "differences.append(0)  # Placeholder value\n",
    "history_length.reverse()\n",
    "differences.reverse()\n",
    "\n",
    "results = []\n",
    "# Initialize timesplits as a list of empty lists for each timesplit\n",
    "timesplits = [[] for _ in range(6)]\n",
    "\n",
    "date_length = env.df_unscaled.shape[0]  # Total number of rows\n",
    "date = env.df_unscaled.index[-date_length]  # Initial start date\n",
    "\n",
    "for j in range(6):  # Loop for 6 time splits\n",
    "    if j != 0:\n",
    "        date_length = date_length // 2  # Halve the date length each iteration\n",
    "    date = env.df_unscaled.index[-date_length]  # Update the start date for the split\n",
    "    \n",
    "    for i in range(len(history_length)):  # Iterate over history lengths\n",
    "        start_date = env.df_unscaled.index[-date_length + sum(differences[:i + 1])]\n",
    "        \n",
    "        # Append the start_date to the corresponding timesplit\n",
    "        timesplits[j].append(start_date)\n",
    "timesplits = pd.DataFrame(timesplits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba076a68-e2c3-45fd-95e7-fe5e53e139f5",
   "metadata": {},
   "source": [
    "Stage 1: Multiple stock learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a2359b9-b6be-470f-91dc-325cb8718909",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/pandas/core/indexing.py:940\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 940\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/pandas/core/indexing.py:1576\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only index by location with a [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Can only index by location with a [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_unscaled\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNVDA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/pandas/core/indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/pandas/core/indexing.py:1652\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m-> 1652\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tuple_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/pandas/core/indexing.py:942\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 942\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    945\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m key\n",
      "\u001b[0;31mValueError\u001b[0m: Location based indexing can only have [integer, integer slice (START point is INCLUDED, END point is EXCLUDED), listlike of integers, boolean array] types"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2478171-7451-466e-9109-1de2ce213d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:450: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  reward_temp = 100 * (next_close_price-close_price) / close_price\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:450: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  reward_temp = 100 * (next_close_price-close_price) / close_price\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:450: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  reward_temp = 100 * (next_close_price-close_price) / close_price\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:450: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  reward_temp = 100 * (next_close_price-close_price) / close_price\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:450: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  reward_temp = 100 * (next_close_price-close_price) / close_price\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:450: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  reward_temp = 100 * (next_close_price-close_price) / close_price\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:442: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  self.shares.append((1 - self.buy_com) * cash_today / close_price)\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:449: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  self.portfolio.append(self.cash[-1] + self.shares[-1] * close_price)\n",
      "/home/studio-lab-user/sagemaker-studiolab-notebooks/AI-OT-24/Reinforcement-Learning-Stock-Porfolio-Managment/./utils/trading_functions.py:450: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  reward_temp = 100 * (next_close_price-close_price) / close_price\n",
      "/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/numpy/core/_methods.py:173: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.0958453553772145, 0.0, 702)\n",
      "inf Inf reward detected: inf\n",
      "(4.0958453553772145, 0.0, 702)\n",
      "inf Inf reward detected: inf\n",
      "(4.0958453553772145, 0.0, 702)\n",
      "inf Inf reward detected: inf\n",
      "(4.0958453553772145, 0.0, 702)\n",
      "inf Inf reward detected: inf\n",
      "(4.0958453553772145, 0.0, 702)\n",
      "inf Inf reward detected: inf\n",
      "(4.0958453553772145, 0.0, 702)\n",
      "inf Inf reward detected: inf\n",
      "(4.0958453553772145, 0.0, 702)\n",
      "inf Inf reward detected: inf\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter logits (Tensor of shape (8, 21)) of distribution Categorical(logits: torch.Size([8, 21])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m         env, vec_env \u001b[38;5;241m=\u001b[39m create_training_env(history_length, reward_type, date, end_date, stocks, n_envs)\n\u001b[1;32m     66\u001b[0m         model\u001b[38;5;241m.\u001b[39mset_env(vec_env)\n\u001b[0;32m---> 67\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA2C\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtimesplit\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m         model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimesplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     77\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/stable_baselines3/a2c/a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:202\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 202\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/stable_baselines3/common/policies.py:654\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# Evaluate the values for the given observations\u001b[39;00m\n\u001b[1;32m    653\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_net(latent_vf)\n\u001b[0;32m--> 654\u001b[0m distribution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_action_dist_from_latent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_pi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m actions \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mget_actions(deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n\u001b[1;32m    656\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m distribution\u001b[38;5;241m.\u001b[39mlog_prob(actions)\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/stable_baselines3/common/policies.py:697\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(mean_actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_std)\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, CategoricalDistribution):\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the logits before the softmax\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproba_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist, MultiCategoricalDistribution):\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# Here mean_actions are the flattened logits\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dist\u001b[38;5;241m.\u001b[39mproba_distribution(action_logits\u001b[38;5;241m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/stable_baselines3/common/distributions.py:288\u001b[0m, in \u001b[0;36mCategoricalDistribution.proba_distribution\u001b[0;34m(self, action_logits)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproba_distribution\u001b[39m(\u001b[38;5;28mself\u001b[39m: SelfCategoricalDistribution, action_logits: th\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfCategoricalDistribution:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m=\u001b[39m \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_logits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/distributions/categorical.py:66\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     65\u001b[0m batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize()\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.10/site-packages/torch/distributions/distribution.py:62\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 62\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     63\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter logits (Tensor of shape (8, 21)) of distribution Categorical(logits: torch.Size([8, 21])) to satisfy the constraint IndependentConstraint(Real(), 1), but found invalid values:\ntensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]])"
     ]
    }
   ],
   "source": [
    "# Example list of 18 stock tickers\n",
    "stock_list = ['NVDA', 'TSLA', 'PLTR', 'AVGO', 'F', 'INTC', 'SMCI', 'MU', 'AAPL', 'AMD', 'PFE', 'T', 'UBER', 'AMZN', 'GOOGL', 'WBD', 'BAC', 'WBA', 'GOOG', 'CVS', 'MSFT', 'CSCO', 'CMCSA', 'WFC', 'KO', 'WMT', 'VZ', 'CCL', 'XOM', 'HBAN', 'AMCR', 'HPE', 'OXY', 'SLB', 'LRCX', 'DVN', 'BA', 'NKE', 'C', 'KDP', 'KHC', 'BMY', 'NEM', 'META', 'KMI', 'PCG', 'CSX', 'AES', 'FCX', 'SCHW', 'GM', 'MRK', 'CVX', 'KEY', 'KVUE', 'MDLZ', 'SBUX', 'DIS', 'HAL', 'UNH', 'MCHP', 'NEE', 'DOW', 'JPM', 'PYPL', 'QCOM', 'EXC', 'JNJ', 'PARA', 'ORCL', 'TFC', 'APH', 'CNC', 'COP', 'ANET', 'USB', 'RF', 'MO', 'HPQ', 'CMG', 'NCLH', 'HST', 'VTRS', 'AMAT', 'WMB', 'ON', 'APA', 'V', 'ADBE', 'WDC', 'GILD', 'EQT', 'MRNA', 'DAL', 'DELL', 'PEP', 'CRM', 'CARR', 'LW', 'MS', 'ABBV', 'EW', 'GIS', 'IPG', 'LUV', 'CTRA', 'GE', 'PG', 'CCI', 'TJX', 'CNP', 'MDT']\n",
    "\n",
    "history_lengths = history_length\n",
    "history_length = None\n",
    "\n",
    "for h_l, history_length in enumerate(history_lengths):\n",
    "    model_save_dir = f'./models/history_length/{history_length}'\n",
    "    log_dir = f'./logs/history_length/{history_length}'\n",
    "    # Split the list into groups of 6 stocks without repetition\n",
    "    n_groups = len(stock_list) // history_length  # This should be 3 for 18/6\n",
    "    groups = [stock_list[i * history_length:(i + 1) * history_length] for i in range(n_groups)]\n",
    "\n",
    "    # Create environments for each group of stocks\n",
    "    env = None\n",
    "    vec_env = None\n",
    "\n",
    "    # Validation environment\n",
    "    valid_env, vec_valid_env = create_evaluation_env(history_length, reward_type, '2023-07-01', '2023-12-30', ['TGT', 'MARA', 'GOOGL', 'WMT', 'V', 'PG'])\n",
    "\n",
    "    # Evaluation callback for saving the best model\n",
    "    eval_callback = EvalCallback(\n",
    "        vec_valid_env,\n",
    "        n_eval_episodes=1,\n",
    "        eval_freq=eval_freq,\n",
    "        deterministic=True,\n",
    "        verbose=0,\n",
    "        best_model_save_path=model_save_dir,\n",
    "    )\n",
    "\n",
    "    _, vec_env = create_training_env(history_length, reward_type, start_date, end_date, groups[0], n_envs)\n",
    "\n",
    "    model = None\n",
    "    model = A2C('MlpPolicy', \n",
    "                    vec_env,\n",
    "                    learning_rate=0.002,\n",
    "                    n_steps=8,\n",
    "                    gamma=0.99,\n",
    "                    gae_lambda=1.0,\n",
    "                    ent_coef=0.05,\n",
    "                    vf_coef=0.5,\n",
    "                    max_grad_norm=0.5,\n",
    "                    rms_prop_eps=1e-05,\n",
    "                    use_rms_prop=True,\n",
    "                    use_sde=False,\n",
    "                    sde_sample_freq=-1,\n",
    "                    rollout_buffer_class=None,\n",
    "                    rollout_buffer_kwargs=None,\n",
    "                    normalize_advantage=False,\n",
    "                    stats_window_size=100,\n",
    "                    tensorboard_log=log_dir,\n",
    "                    policy_kwargs=None,\n",
    "                    verbose=0,\n",
    "                    seed=0,\n",
    "                    device='auto',\n",
    "                    _init_setup_model=True)\n",
    "\n",
    "    for timesplit in range(timesplits.shape[0]):\n",
    "        date = timesplits[h_l][timesplit]\n",
    "        if timesplit != 0:\n",
    "                param = model.get_parameters()\n",
    "                param['policy.optimizer']['param_groups'][0]['lr'] = param['policy.optimizer']['param_groups'][0]['lr']/2\n",
    "                model.set_parameters(param)\n",
    "        for stocks in groups:\n",
    "            env, vec_env = create_training_env(history_length, reward_type, date, end_date, stocks, n_envs)\n",
    "            model.set_env(vec_env)\n",
    "            model.learn(\n",
    "                    total_timesteps=10_000,\n",
    "                    progress_bar=False,\n",
    "                    log_interval=log_interval,\n",
    "                    tb_log_name=f\"A2C{timesplit}\",\n",
    "                    reset_num_timesteps=False,\n",
    "                    callback=eval_callback\n",
    "                )\n",
    "            model.save(f'{model_save_dir}/{timesplit}')\n",
    "\n",
    "    env.close()\n",
    "    vec_env.close()\n",
    "    valid_env.close()\n",
    "    vec_valid_env.close()\n",
    "    del env \n",
    "    del vec_env \n",
    "    del valid_env \n",
    "    del vec_valid_env"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
